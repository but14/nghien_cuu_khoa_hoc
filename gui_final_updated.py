import os
import sys
import time
import logging
from collections import Counter, defaultdict
from typing import Optional, Tuple
from datetime import datetime

import cv2
import numpy as np
import tkinter as tk
from tkinter import messagebox, BooleanVar
from PIL import Image, ImageTk


LOG = logging.getLogger("PastelCameraApp")
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")


class PastelCameraApp:
    """·ª®ng d·ª•ng ghi video + nh·∫≠n di·ªán h√†nh vi & h·ªçc sinh (improved version)."""

    def __init__(self, root: tk.Tk):
        self.root = root
        self.root.title("üéÄ Pastel Camera Recorder üéÄ")
        self.root.geometry("1400x900")
        self.root.configure(bg="#f2e9e4")

        # Camera & video
        self.cap: Optional[cv2.VideoCapture] = None
        self.current_cam_index: Optional[int] = None
        self.frame_size = (960, 540)

        # Recording / counting
        self.counting = False
        self.start_time: Optional[float] = None
        self.recorded_time = 0

        # Detection flags & models
        self.detection_enabled = BooleanVar(value=True)
        self.student_detection_enabled = BooleanVar(value=True)

        self.model = None
        self.student_model = None

        # Model paths
        self.model_path = self.resource_path("model.pt")
        self.student_model_path = self.resource_path("face_classifier.pth")

        # Data structures for counting
        self.behavior_counts: Counter = Counter()
        self.student_behavior_counts: defaultdict = defaultdict(Counter)
        self.current_behaviors: dict = {}
        self.current_student: Optional[str] = None
        
        # NEW: Timeline tracking
        self.behavior_timeline = []  # L∆∞u chi ti·∫øt timeline

        # Timing / cooldowns
        self.last_detected: Optional[str] = None
        self.last_detected_time = 0.0
        self.detection_cooldown = 1.0

        self.last_student_time = 0.0
        self.student_cooldown = 1.5  # Gi·∫£m th·ªùi gian ƒë·ªÉ ph·∫£n h·ªìi nhanh h∆°n
        
        # C·∫£i thi·ªán tracking
        self.student_tracking_history = []  # L∆∞u l·ªãch s·ª≠ tracking
        self.max_tracking_history = 10

        # Confidence threshold
        self.confidence_threshold = 0.65
        
        self.student_names = [f"H·ªçc sinh {i+1}" for i in range(10)]

        self._check_dependencies_and_load_models()
        self._build_ui()
        
        self.root.protocol("WM_DELETE_WINDOW", self.on_close)
        self.update_camera()

    @staticmethod
    def resource_path(relative_path: str) -> str:
        """L·∫•y ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi ƒë·∫øn t√†i nguy√™n (h·ªó tr·ª£ PyInstaller)."""
        try:
            base_path = sys._MEIPASS
        except Exception:
            base_path = os.path.abspath(".")
        return os.path.join(base_path, relative_path)

    def _check_dependencies_and_load_models(self):
        """Ki·ªÉm tra th∆∞ vi·ªán c·∫ßn thi·∫øt v√† t·∫£i m√¥ h√¨nh."""
        self.torch_available = self._is_module_available("torch")
        self.ultralytics_available = self._is_module_available("ultralytics")

        if not (self.torch_available and self.ultralytics_available):
            messagebox.showwarning(
                "C·∫£nh b√°o",
                "Thi·∫øu th∆∞ vi·ªán nh·∫≠n di·ªán: torch v√†/ho·∫∑c ultralytics.\n"
                "B·∫°n c√≥ th·ªÉ c√†i:\n\npip install torch ultralytics\n\n"
                "C√°c t√≠nh nƒÉng nh·∫≠n di·ªán s·∫Ω b·ªã t·∫Øt n·∫øu thi·∫øu."
            )
            if not self.torch_available:
                self.student_detection_enabled.set(False)
            if not (self.torch_available and self.ultralytics_available):
                self.detection_enabled.set(False)

        if self.detection_enabled.get():
            self.load_model()
        if self.student_detection_enabled.get():
            self.load_student_model()

    @staticmethod
    def _is_module_available(mod_name: str) -> bool:
        try:
            __import__(mod_name)
            return True
        except Exception:
            return False

    def load_model(self) -> bool:
        """T·∫£i m√¥ h√¨nh h√†nh vi (YOLOv8 ho·∫∑c YOLOv5)."""
        if not os.path.exists(self.model_path):
            LOG.warning("Model h√†nh vi kh√¥ng t·ªìn t·∫°i: %s", self.model_path)
            self.detection_enabled.set(False)
            return False

        if not (self.torch_available or self.ultralytics_available):
            LOG.warning("Kh√¥ng c√≥ th∆∞ vi·ªán ƒë·ªÉ load model h√†nh vi.")
            self.detection_enabled.set(False)
            return False

        loading = None
        try:
            loading = tk.Toplevel(self.root)
            loading.title("ƒêang t·∫£i m√¥ h√¨nh h√†nh vi")
            loading.geometry("320x100")
            loading.transient(self.root)
            tk.Label(loading, text="ƒêang t·∫£i m√¥ h√¨nh h√†nh vi...\nVui l√≤ng ƒë·ª£i...", font=("Arial", 11)).pack(pady=20)
            loading.update()

            if self.ultralytics_available:
                try:
                    from ultralytics import YOLO
                    self.model = YOLO(self.model_path)
                    LOG.info("ƒê√£ t·∫£i model h√†nh vi (YOLOv8) t·ª´ %s", self.model_path)
                    return True
                except Exception as e:
                    LOG.warning("Kh√¥ng th·ªÉ load YOLOv8: %s", e)

            if self.torch_available:
                try:
                    import torch
                    self.model = torch.hub.load("ultralytics/yolov5", "custom", path=self.model_path, verbose=False)
                    try:
                        self.model.conf = 0.45
                    except Exception:
                        pass
                    LOG.info("ƒê√£ t·∫£i model h√†nh vi (YOLOv5) t·ª´ %s", self.model_path)
                    return True
                except Exception as e:
                    LOG.warning("Kh√¥ng th·ªÉ load YOLOv5: %s", e)

            messagebox.showerror("L·ªói", "Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh h√†nh vi.")
            self.detection_enabled.set(False)
            return False
        finally:
            if loading:
                loading.destroy()

    def load_student_model(self) -> bool:
        """T·∫£i m√¥ h√¨nh nh·∫≠n di·ªán h·ªçc sinh (ResNet18)."""
        if not os.path.exists(self.student_model_path):
            LOG.info("Kh√¥ng t√¨m th·∫•y student model: %s", self.student_model_path)
            self.student_detection_enabled.set(False)
            return False

        if not self.torch_available:
            LOG.warning("torch kh√¥ng c√≥ - kh√¥ng th·ªÉ load student model.")
            self.student_detection_enabled.set(False)
            return False

        loading = None
        try:
            loading = tk.Toplevel(self.root)
            loading.title("ƒêang t·∫£i m√¥ h√¨nh h·ªçc sinh")
            loading.geometry("320x100")
            loading.transient(self.root)
            tk.Label(loading, text="ƒêang t·∫£i m√¥ h√¨nh h·ªçc sinh...\nVui l√≤ng ƒë·ª£i...", font=("Arial", 11)).pack(pady=20)
            loading.update()

            try:
                import torch
                import torchvision.models as models

                num_classes = max(10, len(self.student_names))
                model = models.resnet18(pretrained=False)
                model.fc = torch.nn.Linear(model.fc.in_features, num_classes)
                state = torch.load(self.student_model_path, map_location=torch.device("cpu"))
                model.load_state_dict(state)
                model.eval()
                self.student_model = model
                LOG.info("ƒê√£ t·∫£i student model d·∫°ng ResNet t·ª´ %s", self.student_model_path)
                return True
            except Exception as e:
                LOG.warning("Kh√¥ng th·ªÉ load student model d∆∞·ªõi d·∫°ng ResNet: %s", e)

            if self.ultralytics_available:
                try:
                    from ultralytics import YOLO
                    self.student_model = YOLO(self.student_model_path)
                    LOG.info("ƒê√£ t·∫£i student model (YOLOv8) t·ª´ %s", self.student_model_path)
                    return True
                except Exception as e:
                    LOG.warning("Kh√¥ng th·ªÉ load student YOLOv8: %s", e)

            messagebox.showwarning("C·∫£nh b√°o", "Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh h·ªçc sinh.")
            self.student_detection_enabled.set(False)
            return False
        finally:
            if loading:
                loading.destroy()

    def _build_ui(self):
        """T·∫°o UI ch√≠nh."""
        # Select frame
        self.select_frame = tk.Frame(self.root, bg="#f2e9e4")
        self.select_frame.pack(fill="both", expand=True)

        title = tk.Label(self.select_frame, text="Ch·ªçn ngu·ªìn camera", bg="#f2e9e4", font=("Arial", 18, "bold"))
        title.pack(pady=(30, 10))

        top_frame = tk.Frame(self.select_frame, bg="#f2e9e4")
        top_frame.pack(pady=(15, 5))

        tk.Label(top_frame, text="Ngu·ªìn camera:", bg="#f2e9e4", font=("Arial", 12, "bold")).grid(row=0, column=0, padx=(0, 10))
        self.cam_var = tk.StringVar(value="0")

        rb_internal = tk.Radiobutton(top_frame, text="Camera m√°y t√≠nh (0)", variable=self.cam_var, value="0", bg="#f2e9e4", font=("Arial", 11))
        rb_external = tk.Radiobutton(top_frame, text="Camera r·ªùi (1)", variable=self.cam_var, value="1", bg="#f2e9e4", font=("Arial", 11))
        rb_internal.grid(row=0, column=1, padx=10)
        rb_external.grid(row=0, column=2, padx=10)

        apply_btn = tk.Button(self.select_frame, text="√Åp d·ª•ng ngu·ªìn", command=self.apply_camera_choice_and_go,
                              bg="#ffffff", activebackground="#fde2e4", relief="raised", bd=2, font=("Arial", 12, "bold"), cursor="hand2")
        apply_btn.pack(pady=20)

        # Main frame
        self.main_frame = tk.Frame(self.root, bg="#f2e9e4")

        # Top bar
        top_bar = tk.Frame(self.main_frame, bg="#f2e9e4")
        top_bar.pack(pady=(10, 0), fill="x")

        self.back_btn = tk.Button(top_bar, text="‚üµ Quay l·∫°i ch·ªçn ngu·ªìn", command=self.go_back_to_select,
                                  bg="#ffffff", activebackground="#fde2e4", relief="raised", bd=2, font=("Arial", 11, "bold"), cursor="hand2")
        self.back_btn.pack(side="left", padx=20)

        # Checkbuttons
        self.student_detection_cb = tk.Checkbutton(top_bar, text="Nh·∫≠n di·ªán h·ªçc sinh", variable=self.student_detection_enabled,
                                                   bg="#f2e9e4", font=("Arial", 11, "bold"), command=self.toggle_student_detection)
        self.student_detection_cb.pack(side="right", padx=10)
        if self.student_detection_enabled.get():
            self.student_detection_cb.select()

        self.detection_cb = tk.Checkbutton(top_bar, text="Nh·∫≠n di·ªán h√†nh vi", variable=self.detection_enabled,
                                           bg="#f2e9e4", font=("Arial", 11, "bold"), command=self.toggle_detection)
        self.detection_cb.pack(side="right", padx=10)
        if self.detection_enabled.get():
            self.detection_cb.select()

        # NEW: Confidence threshold control
        conf_frame = tk.Frame(self.main_frame, bg="#f2e9e4")
        conf_frame.pack(pady=5)
        
        tk.Label(conf_frame, text="Ng∆∞·ª°ng tin c·∫≠y:", bg="#f2e9e4", font=("Arial", 10, "bold")).pack(side="left", padx=5)
        self.conf_scale = tk.Scale(conf_frame, from_=0.5, to=0.95, resolution=0.05,
                                   orient="horizontal", bg="#f2e9e4", length=200,
                                   command=self.update_confidence_threshold)
        self.conf_scale.set(self.confidence_threshold)
        self.conf_scale.pack(side="left")
        
        self.conf_value_label = tk.Label(conf_frame, text=f"{self.confidence_threshold:.2f}", bg="#f2e9e4", font=("Arial", 10, "bold"))
        self.conf_value_label.pack(side="left", padx=5)

        # Buttons frame
        btn_frame = tk.Frame(self.main_frame, bg="#f2e9e4")
        btn_frame.pack(pady=12, fill="x")

        btn_style = {"width": 14, "height": 3, "compound": "top",
                     "bg": "#fff", "activebackground": "#fde2e4",
                     "relief": "raised", "bd": 2, "font": ("Arial", 11, "bold"),
                     "cursor": "hand2"}

        start_icon = self._safe_load_icon("start.png", (64, 64))
        stop_icon = self._safe_load_icon("stop.png", (64, 64))
        report_icon = self._safe_load_icon("report.png", (64, 64))

        self.start_btn = tk.Button(btn_frame, text="B·∫Øt ƒë·∫ßu", image=start_icon, command=self.start_counting, **btn_style)
        self.start_btn.image = start_icon
        self.start_btn.pack(side="left", padx=40)

        self.stop_btn = tk.Button(btn_frame, text="D·ª´ng", image=stop_icon, command=self.stop_counting, **btn_style)
        self.stop_btn.image = stop_icon
        self.stop_btn.pack(side="left", padx=40)

        self.report_btn = tk.Button(btn_frame, text="B√°o c√°o", image=report_icon, command=self.show_behavior_report, **btn_style)
        self.report_btn.image = report_icon
        self.report_btn.pack(side="left", padx=40)

        # Video display
        self.video_label = tk.Label(self.main_frame, bg="#c9ada7")
        self.video_label.pack(pady=10, fill="both", expand=True)

        # Count frame
        self.count_frame = tk.Frame(self.main_frame, bg="#f2e9e4")
        self.count_frame.pack(pady=5, fill="x")

        self.count_label = tk.Label(self.count_frame, text="ƒêang ch·ªù b·∫Øt ƒë·∫ßu ƒë·∫øm...", bg="#f2e9e4", font=("Arial", 12), fg="#2d3436")
        self.count_label.pack(pady=5)

        self.info_label = tk.Label(self.main_frame, text="üü° Ch∆∞a m·ªü camera. H√£y quay l·∫°i ch·ªçn ngu·ªìn v√† √°p d·ª•ng.",
                                   bg="#f2e9e4", font=("Arial", 14, "bold"), fg="#2d3436")
        self.info_label.pack(pady=8)

    def _safe_load_icon(self, name: str, size: Tuple[int, int]) -> Optional[ImageTk.PhotoImage]:
        """T·∫£i icon n·∫øu c√≥, tr·∫£ v·ªÅ None n·∫øu l·ªói."""
        try:
            path = self.resource_path(name)
            img = Image.open(path).resize(size)
            return ImageTk.PhotoImage(img)
        except Exception:
            return None

    def update_confidence_threshold(self, value):
        """C·∫≠p nh·∫≠t ng∆∞·ª°ng tin c·∫≠y."""
        self.confidence_threshold = float(value)
        self.conf_value_label.config(text=f"{self.confidence_threshold:.2f}")

    def init_camera(self, index: int) -> bool:
        """Kh·ªüi t·∫°o camera."""
        try:
            if self.cap and getattr(self.cap, "isOpened", lambda: False)():
                try:
                    self.cap.release()
                except Exception:
                    pass
            
            if sys.platform.startswith("win"):
                self.cap = cv2.VideoCapture(index, cv2.CAP_DSHOW)
            else:
                self.cap = cv2.VideoCapture(index)
            
            ok = self.cap.isOpened()
            if ok:
                self.current_cam_index = index
                LOG.info("M·ªü camera %s th√†nh c√¥ng", index)
            else:
                self.current_cam_index = None
                LOG.warning("Kh√¥ng m·ªü ƒë∆∞·ª£c camera %s", index)
            return ok
        except Exception as e:
            LOG.exception("L·ªói init_camera: %s", e)
            return False

    def apply_camera_choice_and_go(self):
        """X·ª≠ l√Ω khi ·∫•n '√Åp d·ª•ng ngu·ªìn'."""
        if self.counting:
            messagebox.showwarning("ƒêang ƒë·∫øm", "Vui l√≤ng d·ª´ng ƒë·∫øm tr∆∞·ªõc khi ƒë·ªïi ngu·ªìn.")
            return

        cam_index = int(self.cam_var.get())
        if not self.init_camera(cam_index):
            alt = 1 - cam_index
            if self.init_camera(alt):
                self.cam_var.set(str(alt))
                messagebox.showwarning("Ch√∫ √Ω", f"Kh√¥ng m·ªü ƒë∆∞·ª£c camera {cam_index}. ƒê√£ chuy·ªÉn sang {alt}.")
            else:
                messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ m·ªü camera {cam_index} v√† {alt}.")
                return

        self.show_main_ui()
        status = f"üü¢ Camera {self.current_cam_index} ƒëang b·∫≠t"
        if self.student_detection_enabled.get() and self.detection_enabled.get():
            status += " v·ªõi nh·∫≠n di·ªán h·ªçc sinh v√† h√†nh vi"
        elif self.student_detection_enabled.get():
            status += " v·ªõi nh·∫≠n di·ªán h·ªçc sinh"
        elif self.detection_enabled.get():
            status += " v·ªõi nh·∫≠n di·ªán h√†nh vi"
        else:
            status += " ‚Äì s·∫µn s√†ng ƒë·∫øm."
        self.info_label.config(text=status)

    def go_back_to_select(self):
        if self.counting:
            messagebox.showwarning("ƒêang ƒë·∫øm", "H√£y d·ª´ng ƒë·∫øm tr∆∞·ªõc khi quay l·∫°i.")
            return
        self.main_frame.pack_forget()
        self.select_frame.pack(fill="both", expand=True)

    def show_main_ui(self):
        self.select_frame.pack_forget()
        self.main_frame.pack(fill="both", expand=True)

    def detect_face(self, frame: np.ndarray) -> Tuple[Optional[np.ndarray], Optional[Tuple[int, int, int, int]]]:
        """D√πng Haar Cascade ƒë·ªÉ detect khu√¥n m·∫∑t."""
        try:
            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            
            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, 
                                                 minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)
            
            if len(faces) == 0:
                return None, None
                
            x, y, w, h = max(faces, key=lambda r: r[2] * r[3])
            
            y_offset = int(h * 0.1)
            x_offset = int(w * 0.05)
            
            y1 = max(0, y - y_offset)
            y2 = min(frame.shape[0], y + h + y_offset)
            x1 = max(0, x - x_offset)
            x2 = min(frame.shape[1], x + w + x_offset)
            
            face_img = frame[y1:y2, x1:x2]
            return face_img, (x1, y1, x2-x1, y2-y1)
        except Exception as e:
            LOG.exception("L·ªói detect_face: %s", e)
            return None, None

    def preprocess_face_image(self, face_img: np.ndarray):
        """Ti·ªÅn x·ª≠ l√Ω ·∫£nh khu√¥n m·∫∑t cho ResNet."""
        try:
            import torch
            import torchvision.transforms as transforms

            transform = transforms.Compose([
                transforms.ToPILImage(),
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ])
            tensor = transform(face_img).unsqueeze(0)
            return tensor
        except Exception as e:
            LOG.exception("L·ªói preprocess_face_image: %s", e)
            return None

    @staticmethod
    def calculate_iou(box1, box2):
        """T√≠nh IoU gi·ªØa 2 bounding boxes (x, y, w, h)."""
        x1, y1, w1, h1 = box1
        x2, y2, w2, h2 = box2
        
        box1_x2, box1_y2 = x1 + w1, y1 + h1
        box2_x2, box2_y2 = x2 + w2, y2 + h2
        
        xi1 = max(x1, x2)
        yi1 = max(y1, y2)
        xi2 = min(box1_x2, box2_x2)
        yi2 = min(box1_y2, box2_y2)
        
        inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)
        
        box1_area = w1 * h1
        box2_area = w2 * h2
        union_area = box1_area + box2_area - inter_area
        
        return inter_area / union_area if union_area > 0 else 0

    def is_face_in_behavior_box(self, face_bbox, behavior_bbox, threshold=0.2):
        """Ki·ªÉm tra khu√¥n m·∫∑t c√≥ n·∫±m trong v√πng h√†nh vi kh√¥ng."""
        if not face_bbox or not behavior_bbox:
            return False
        
        x1, y1, x2, y2 = behavior_bbox
        behavior_box_xywh = (x1, y1, x2-x1, y2-y1)
        
        iou = self.calculate_iou(face_bbox, behavior_box_xywh)
        return iou > threshold
    
    def calculate_distance_between_boxes(self, face_bbox, behavior_bbox):
        """T√≠nh kho·∫£ng c√°ch gi·ªØa center c·ªßa hai bounding box."""
        if not face_bbox or not behavior_bbox:
            return float('inf')
        
        fx, fy, fw, fh = face_bbox
        bx1, by1, bx2, by2 = behavior_bbox
        
        # Center c·ªßa face box
        face_center_x = fx + fw // 2
        face_center_y = fy + fh // 2
        
        # Center c·ªßa behavior box
        behavior_center_x = (bx1 + bx2) // 2
        behavior_center_y = (by1 + by2) // 2
        
        # T√≠nh kho·∫£ng c√°ch Euclidean
        distance = ((face_center_x - behavior_center_x) ** 2 + 
                   (face_center_y - behavior_center_y) ** 2) ** 0.5
        
        return distance
    
    def get_most_recent_student(self):
        """L·∫•y h·ªçc sinh ƒë∆∞·ª£c nh·∫≠n di·ªán g·∫ßn ƒë√¢y nh·∫•t."""
        if not self.student_tracking_history:
            return None
        
        # L·∫•y entry g·∫ßn nh·∫•t
        most_recent = self.student_tracking_history[-1]
        now = time.time()
        
        # Ki·ªÉm tra xem c√≥ trong v√≤ng 3 gi√¢y kh√¥ng
        if now - most_recent['timestamp'] < 3.0:
            return most_recent['name']
        
        return None

    def detect_objects_and_count(self, frame: np.ndarray) -> np.ndarray:
        """Nh·∫≠n di·ªán h√†nh vi + h·ªçc sinh v√† li√™n k·∫øt ch√∫ng."""
        annotated_frame = frame.copy()
        
        # B∆∞·ªõc 1: Nh·∫≠n di·ªán khu√¥n m·∫∑t h·ªçc sinh
        student_name = None
        face_bbox = None
        
        if self.student_detection_enabled.get() and self.student_model is not None:
            now = time.time()
            if now - self.last_student_time > self.student_cooldown:
                face_img, face_bbox = self.detect_face(frame)
                if face_img is not None and face_bbox is not None:
                    # Nh·∫≠n di·ªán b·∫±ng ResNet
                    if "ResNet" in str(type(self.student_model)):
                        tensor = self.preprocess_face_image(face_img)
                        if tensor is not None:
                            import torch
                            with torch.no_grad():
                                outputs = self.student_model(tensor)
                                probs = torch.nn.functional.softmax(outputs, dim=1)
                                conf, pred = torch.max(probs, dim=1)
                                conf_val = float(conf.item())
                                idx = int(pred.item())
                            
                            if conf_val > self.confidence_threshold and idx < len(self.student_names):
                                student_name = self.student_names[idx]
                                self.current_student = student_name
                                self.last_student_time = now
                                
                                # C·∫≠p nh·∫≠t tracking history
                                self.student_tracking_history.append({
                                    'name': student_name,
                                    'confidence': conf_val,
                                    'timestamp': now,
                                    'bbox': face_bbox
                                })
                                
                                # Gi·ªõi h·∫°n l·ªãch s·ª≠
                                if len(self.student_tracking_history) > self.max_tracking_history:
                                    self.student_tracking_history.pop(0)
                                
                                # V·∫Ω box khu√¥n m·∫∑t v·ªõi m√†u s·∫Øc kh√°c bi·ªát
                                x, y, w, h = face_bbox
                                cv2.rectangle(annotated_frame, (x, y), (x+w, y+h), (255, 0, 255), 3)
                                
                                # V·∫Ω label v·ªõi background
                                label = f"{student_name} ({conf_val:.2f})"
                                (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)
                                cv2.rectangle(annotated_frame, (x, y-label_h-15), (x+label_w+10, y-5), (255, 0, 255), -1)
                                cv2.putText(annotated_frame, label, (x+5, y-8), 
                                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

        # B∆∞·ªõc 2: Nh·∫≠n di·ªán h√†nh vi
        if self.model is None or not self.detection_enabled.get():
            return annotated_frame

        try:
            results = self.model(frame)
            behavior_detections = []
            
            # Parse YOLO results
            if "ultralytics.engine.results.Results" in str(type(results)):
                if hasattr(results[0], "boxes") and len(results[0].boxes) > 0:
                    for box in results[0].boxes:
                        cls_id = int(box.cls[0])
                        conf = float(box.conf[0])
                        
                        if conf < self.confidence_threshold:
                            continue
                            
                        x1, y1, x2, y2 = map(int, box.xyxy[0])
                        
                        if hasattr(results[0], "names") and cls_id in results[0].names:
                            behavior_name = results[0].names[cls_id]
                            behavior_detections.append({
                                'name': behavior_name,
                                'conf': conf,
                                'bbox': (x1, y1, x2, y2)
                            })
            else:
                # YOLOv5 format
                if hasattr(results, "pred") and len(results.pred) > 0:
                    for det in results.pred[0]:
                        det = det.cpu().numpy()
                        if len(det) >= 6:
                            conf = float(det[4])
                            if conf < self.confidence_threshold:
                                continue
                                
                            cls_id = int(det[5])
                            x1, y1, x2, y2 = map(int, det[:4])
                            
                            if hasattr(results, "names") and cls_id in results.names:
                                behavior_name = results.names[cls_id]
                                behavior_detections.append({
                                    'name': behavior_name,
                                    'conf': conf,
                                    'bbox': (x1, y1, x2, y2)
                                })
            
            # B∆∞·ªõc 3: Li√™n k·∫øt h·ªçc sinh v·ªõi h√†nh vi
            matched_behaviors = []
            
            for detection in behavior_detections:
                behavior_name = detection['name']
                behavior_conf = detection['conf']
                behavior_bbox = detection['bbox']
                x1, y1, x2, y2 = behavior_bbox
                
                # Ki·ªÉm tra li√™n k·∫øt v·ªõi h·ªçc sinh (c·∫£i thi·ªán logic)
                assigned_student = None
                if student_name and face_bbox:
                    # Ki·ªÉm tra IoU gi·ªØa khu√¥n m·∫∑t v√† h√†nh vi
                    if self.is_face_in_behavior_box(face_bbox, behavior_bbox, threshold=0.15):
                        assigned_student = student_name
                    # N·∫øu kh√¥ng c√≥ IoU t·ªët, ki·ªÉm tra kho·∫£ng c√°ch
                    elif self.calculate_distance_between_boxes(face_bbox, behavior_bbox) < 100:
                        # Ki·ªÉm tra l·ªãch s·ª≠ tracking g·∫ßn ƒë√¢y
                        recent_student = self.get_most_recent_student()
                        if recent_student and recent_student == student_name:
                            assigned_student = student_name
                
                # V·∫Ω bounding box
                color = (0, 255, 0) if assigned_student else (0, 165, 255)
                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)
                
                # T·∫°o label
                if assigned_student:
                    label = f"{assigned_student}: {behavior_name} {behavior_conf:.2f}"
                else:
                    label = f"{behavior_name} {behavior_conf:.2f}"
                
                # V·∫Ω label v·ªõi background
                (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
                cv2.rectangle(annotated_frame, (x1, y1-label_h-10), (x1+label_w, y1), color, -1)
                cv2.putText(annotated_frame, label, (x1, y1-5), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                matched_behaviors.append({
                    'student': assigned_student or "Unknown",
                    'behavior': behavior_name,
                    'conf': behavior_conf,
                    'timestamp': time.time()
                })
            
            # B∆∞·ªõc 4: C·∫≠p nh·∫≠t ƒë·∫øm v√† timeline
            now = time.time()
            if self.counting and matched_behaviors:
                for match in matched_behaviors:
                    if now - self.last_detected_time > self.detection_cooldown:
                        behavior = match['behavior']
                        student = match['student']
                        
                        self.behavior_counts[behavior] += 1
                        
                        if student != "Unknown":
                            self.student_behavior_counts[student][behavior] += 1
                            self.current_behaviors[student] = behavior
                        
                        # L∆∞u v√†o timeline
                        self.behavior_timeline.append({
                            'time': datetime.now().strftime('%H:%M:%S'),
                            'student': student,
                            'behavior': behavior,
                            'confidence': match['conf']
                        })
                        
                        self.last_detected = behavior
                        self.last_detected_time = now
                        self.update_count_display()
            
            return annotated_frame
            
        except Exception as e:
            LOG.exception("L·ªói detect_objects_and_count: %s", e)
            return annotated_frame

    def toggle_detection(self):
        if self.detection_enabled.get():
            if not (self.torch_available or self.ultralytics_available):
                self.detection_enabled.set(False)
                messagebox.showerror("L·ªói", "Thi·∫øu th∆∞ vi·ªán: pip install torch ultralytics")
                return
            if self.model is None and not self.load_model():
                self.detection_enabled.set(False)
                return
            messagebox.showinfo("Th√¥ng b√°o", "ƒê√£ b·∫≠t nh·∫≠n di·ªán h√†nh vi.")
        else:
            messagebox.showinfo("Th√¥ng b√°o", "ƒê√£ t·∫Øt nh·∫≠n di·ªán h√†nh vi.")

    def toggle_student_detection(self):
        if self.student_detection_enabled.get():
            if not self.torch_available:
                self.student_detection_enabled.set(False)
                messagebox.showerror("L·ªói", "Thi·∫øu torch: pip install torch")
                return
            if self.student_model is None and not self.load_student_model():
                self.student_detection_enabled.set(False)
                return
            messagebox.showinfo("Th√¥ng b√°o", "ƒê√£ b·∫≠t nh·∫≠n di·ªán h·ªçc sinh.")
        else:
            self.current_student = None
            messagebox.showinfo("Th√¥ng b√°o", "ƒê√£ t·∫Øt nh·∫≠n di·ªán h·ªçc sinh.")

    def start_counting(self):
        if not (self.cap and getattr(self.cap, "isOpened", lambda: False)()):
            messagebox.showerror("L·ªói", "Ch∆∞a c√≥ camera n√†o ƒëang m·ªü.")
            return
        if not self.detection_enabled.get():
            messagebox.showerror("L·ªói", "Vui l√≤ng b·∫≠t nh·∫≠n di·ªán h√†nh vi tr∆∞·ªõc khi ƒë·∫øm.")
            return
        if self.counting:
            messagebox.showinfo("Th√¥ng b√°o", "ƒê√£ ƒëang ƒë·∫øm.")
            return

        # Reset counters
        self.behavior_counts = Counter()
        self.student_behavior_counts = defaultdict(Counter)
        self.current_behaviors = {}
        self.behavior_timeline = []
        self.last_detected = None
        self.last_detected_time = 0.0

        self.counting = True
        self.start_time = time.time()
        self.recorded_time = 0
        
        if self.student_detection_enabled.get():
            status = f"üî¥ ƒêang ƒë·∫øm h√†nh vi theo h·ªçc sinh (camera {self.current_cam_index})..."
            if self.current_student:
                self.count_label.config(text=f"ƒêang ƒë·∫øm cho h·ªçc sinh: {self.current_student}...\nCh∆∞a ph√°t hi·ªán h√†nh vi.")
            else:
                self.count_label.config(text="ƒêang ƒë·∫øm h√†nh vi...\nƒêang ƒë·ª£i nh·∫≠n di·ªán h·ªçc sinh.")
            messagebox.showinfo("Th√¥ng b√°o", "B·∫Øt ƒë·∫ßu ƒë·∫øm h√†nh vi theo h·ªçc sinh!")
        else:
            status = f"üî¥ ƒêang ƒë·∫øm h√†nh vi (camera {self.current_cam_index})..."
            self.count_label.config(text="ƒêang ƒë·∫øm h√†nh vi...\nCh∆∞a ph√°t hi·ªán h√†nh vi.")
            messagebox.showinfo("Th√¥ng b√°o", "B·∫Øt ƒë·∫ßu ƒë·∫øm h√†nh vi!")

        self.info_label.config(text=status)

    def stop_counting(self):
        if not self.counting:
            messagebox.showinfo("Th√¥ng b√°o", "Ch∆∞a b·∫Øt ƒë·∫ßu ƒë·∫øm h√†nh vi.")
            return
        self.counting = False
        self.recorded_time = int(time.time() - self.start_time) if self.start_time else 0
        status = f"üü° ƒê√£ d·ª´ng ƒë·∫øm. Th·ªùi gian: {self.recorded_time} gi√¢y (camera {self.current_cam_index})"
        self.info_label.config(text=status)
        self.show_behavior_report()
        self.save_behavior_report()

    def update_count_display(self):
        """C·∫≠p nh·∫≠t label hi·ªÉn th·ªã k·∫øt qu·∫£ ƒë·∫øm."""
        if not self.counting:
            return
        
        if self.current_student:
            lines = [f"H·ªçc sinh hi·ªán t·∫°i: {self.current_student}", "", "S·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa c√°c h√†nh vi:"]
            beh = self.student_behavior_counts.get(self.current_student, {})
            if beh:
                for b, c in sorted(beh.items()):
                    lines.append(f"- {b}: {c} l·∫ßn")
            else:
                lines.append("Ch∆∞a ph√°t hi·ªán h√†nh vi n√†o.")
            cur = self.current_behaviors.get(self.current_student)
            if cur:
                lines.append("")
                lines.append(f"H√†nh vi hi·ªán t·∫°i: {cur}")
        else:
            lines = ["S·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa c√°c h√†nh vi:"]
            if self.behavior_counts:
                for b, c in sorted(self.behavior_counts.items()):
                    lines.append(f"- {b}: {c} l·∫ßn")
            else:
                lines.append("Ch∆∞a ph√°t hi·ªán h√†nh vi n√†o.")
            if self.student_detection_enabled.get():
                lines.append("")
                lines.append("(ƒêang ƒë·ª£i nh·∫≠n di·ªán h·ªçc sinh...)")
        
        self.count_label.config(text="\n".join(lines))

    def save_behavior_report(self):
        """L∆∞u b√°o c√°o text v√†o th∆∞ m·ª•c reports."""
        os.makedirs("reports", exist_ok=True)
        fname = time.strftime("reports/behavior_report_%Y%m%d_%H%M%S.txt")
        try:
            with open(fname, "w", encoding="utf-8") as f:
                f.write(f"B√ÅO C√ÅO H√ÄNH VI - {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"Th·ªùi gian ƒë·∫øm: {self.recorded_time} gi√¢y\n")
                f.write(f"Camera: {self.current_cam_index}\n")
                f.write(f"Ng∆∞·ª°ng tin c·∫≠y: {self.confidence_threshold:.2f}\n\n")
                
                if self.student_detection_enabled.get() and self.student_behavior_counts:
                    f.write("B√ÅO C√ÅO THEO H·ªåC SINH:\n=====================\n\n")
                    for student, behaviors in sorted(self.student_behavior_counts.items()):
                        f.write(f"H·ªçc sinh: {student}\n")
                        if behaviors:
                            total = sum(behaviors.values())
                            for b, c in sorted(behaviors.items()):
                                percentage = (c / total * 100) if total > 0 else 0
                                f.write(f"  - {b}: {c} l·∫ßn ({percentage:.1f}%)\n")
                        else:
                            f.write("  Kh√¥ng ph√°t hi·ªán h√†nh vi n√†o.\n")
                        f.write("\n")
                    f.write("\nT·ªîNG H·ª¢P T·∫§T C·∫¢ H√ÄNH VI:\n=====================\n\n")
                
                f.write("S·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa c√°c h√†nh vi:\n")
                if self.behavior_counts:
                    for b, c in sorted(self.behavior_counts.items()):
                        f.write(f"- {b}: {c} l·∫ßn\n")
                else:
                    f.write("Kh√¥ng ph√°t hi·ªán h√†nh vi n√†o.\n")
                
                # Th√™m timeline
                if self.behavior_timeline:
                    f.write("\n\nTIMELINE CHI TI·∫æT:\n=====================\n")
                    for entry in self.behavior_timeline:
                        f.write(f"{entry['time']} - {entry['student']}: {entry['behavior']} (conf: {entry['confidence']:.2f})\n")
            
            messagebox.showinfo("Th√†nh c√¥ng", f"ƒê√£ l∆∞u b√°o c√°o: {fname}")
        except Exception as e:
            LOG.exception("L·ªói save_behavior_report: %s", e)
            messagebox.showerror("L·ªói", f"Kh√¥ng l∆∞u ƒë∆∞·ª£c b√°o c√°o: {e}")

    def show_behavior_report(self):
        """Hi·ªÉn th·ªã b√°o c√°o chi ti·∫øt."""
        report_window = tk.Toplevel(self.root)
        report_window.title("üìä B√°o c√°o h√†nh vi")
        report_window.geometry("800x800")
        report_window.configure(bg="#f2e9e4")

        text_frame = tk.Frame(report_window, bg="#f2e9e4")
        text_frame.pack(fill="both", expand=True, padx=20, pady=20)

        scrollbar = tk.Scrollbar(text_frame)
        scrollbar.pack(side="right", fill="y")

        text_widget = tk.Text(text_frame, wrap="word", font=("Arial", 11), bg="#ffffff")
        text_widget.pack(side="left", fill="both", expand=True)
        scrollbar.config(command=text_widget.yview)
        text_widget.config(yscrollcommand=scrollbar.set)

        report = []
        report.append("=" * 60 + "\n")
        report.append("B√ÅO C√ÅO H√ÄNH VI H·ªåC SINH\n")
        report.append("=" * 60 + "\n\n")
        
        if hasattr(self, "recorded_time") and self.recorded_time:
            report.append(f"‚è±Ô∏è  Th·ªùi gian ƒë·∫øm: {self.recorded_time} gi√¢y\n")
        report.append(f"üéØ Ng∆∞·ª°ng tin c·∫≠y: {self.confidence_threshold:.2f}\n")
        report.append(f"üì∑ Camera: {self.current_cam_index}\n\n")

        if self.student_detection_enabled.get() and self.student_behavior_counts:
            report.append("üë• B√ÅO C√ÅO THEO H·ªåC SINH:\n")
            report.append("=" * 60 + "\n\n")
            
            for student, behaviors in sorted(self.student_behavior_counts.items()):
                report.append(f"üìå {student}\n")
                report.append("-" * 40 + "\n")
                if behaviors:
                    total = sum(behaviors.values())
                    for b, c in sorted(behaviors.items(), key=lambda x: x[1], reverse=True):
                        percentage = (c / total * 100) if total > 0 else 0
                        bar = "‚ñà" * int(percentage / 5)
                        report.append(f"  ‚Ä¢ {b}: {c} l·∫ßn ({percentage:.1f}%) {bar}\n")
                else:
                    report.append("  Kh√¥ng ph√°t hi·ªán h√†nh vi n√†o.\n")
                report.append("\n")
            
            report.append("\nüìä T·ªîNG H·ª¢P T·∫§T C·∫¢ H√ÄNH VI:\n")
            report.append("=" * 60 + "\n\n")

        report.append("üìà S·ªë l·∫ßn xu·∫•t hi·ªán:\n")
        report.append("-" * 40 + "\n")
        if self.behavior_counts:
            total_all = sum(self.behavior_counts.values())
            for b, c in sorted(self.behavior_counts.items(), key=lambda x: x[1], reverse=True):
                percentage = (c / total_all * 100) if total_all > 0 else 0
                bar = "‚ñà" * int(percentage / 5)
                report.append(f"  ‚Ä¢ {b}: {c} l·∫ßn ({percentage:.1f}%) {bar}\n")
        else:
            report.append("  Kh√¥ng ph√°t hi·ªán h√†nh vi n√†o.\n")

        # Timeline
        if self.behavior_timeline:
            report.append("\n\n‚è∞ TIMELINE CHI TI·∫æT:\n")
            report.append("=" * 60 + "\n\n")
            for entry in self.behavior_timeline[-20:]:  # Ch·ªâ hi·ªÉn th·ªã 20 m·ª•c g·∫ßn nh·∫•t
                report.append(f"{entry['time']} | {entry['student']:15} | {entry['behavior']:15} | {entry['confidence']:.2f}\n")
            if len(self.behavior_timeline) > 20:
                report.append(f"\n... v√† {len(self.behavior_timeline) - 20} m·ª•c kh√°c\n")

        text_widget.insert("1.0", "".join(report))
        text_widget.config(state="disabled")

        # Buttons
        btn_frame = tk.Frame(report_window, bg="#f2e9e4")
        btn_frame.pack(pady=10)

        save_btn = tk.Button(btn_frame, text="üíæ L∆∞u b√°o c√°o", command=self.save_behavior_report,
                             bg="#ffffff", activebackground="#fde2e4", relief="raised", 
                             bd=2, font=("Arial", 11, "bold"), cursor="hand2", width=15)
        save_btn.pack(side="left", padx=5)

        try:
            import pandas as pd  # noqa: F401
            excel_btn = tk.Button(btn_frame, text="üìä Xu·∫•t Excel", command=self.export_excel_report,
                                  bg="#ffffff", activebackground="#d0f0c0", relief="raised", 
                                  bd=2, font=("Arial", 11, "bold"), cursor="hand2", width=15)
            excel_btn.pack(side="left", padx=5)
        except Exception:
            pass

    def export_excel_report(self):
        """Xu·∫•t b√°o c√°o sang Excel v·ªõi timeline."""
        try:
            import pandas as pd
            os.makedirs("reports", exist_ok=True)
            excel_file = time.strftime("reports/behavior_report_%Y%m%d_%H%M%S.xlsx")

            with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
                # Sheet 1: T·ªïng h·ª£p
                summary_data = [{"H√†nh vi": b, "S·ªë l·∫ßn xu·∫•t hi·ªán": c, 
                                "T·ª∑ l·ªá (%)": round(c/sum(self.behavior_counts.values())*100, 2) if sum(self.behavior_counts.values()) > 0 else 0} 
                               for b, c in sorted(self.behavior_counts.items())]
                if summary_data:
                    pd.DataFrame(summary_data).to_excel(writer, sheet_name="T·ªïng h·ª£p", index=False)
                
                # Sheet 2: Chi ti·∫øt theo h·ªçc sinh
                student_data = []
                for student, behaviors in sorted(self.student_behavior_counts.items()):
                    total = sum(behaviors.values())
                    for b, c in sorted(behaviors.items()):
                        student_data.append({
                            "H·ªçc sinh": student,
                            "H√†nh vi": b,
                            "S·ªë l·∫ßn": c,
                            "T·ª∑ l·ªá (%)": round(c/total*100, 2) if total > 0 else 0
                        })
                
                if student_data:
                    pd.DataFrame(student_data).to_excel(writer, sheet_name="Theo h·ªçc sinh", index=False)
                
                # Sheet 3: Timeline
                if self.behavior_timeline:
                    timeline_df = pd.DataFrame(self.behavior_timeline)
                    timeline_df.to_excel(writer, sheet_name="Timeline", index=False)
                
                # Sheet 4: Th·ªëng k√™ t·ªïng quan
                stats_data = [{
                    "Ch·ªâ s·ªë": "T·ªïng s·ªë s·ª± ki·ªán",
                    "Gi√° tr·ªã": sum(self.behavior_counts.values())
                }, {
                    "Ch·ªâ s·ªë": "S·ªë lo·∫°i h√†nh vi",
                    "Gi√° tr·ªã": len(self.behavior_counts)
                }, {
                    "Ch·ªâ s·ªë": "S·ªë h·ªçc sinh",
                    "Gi√° tr·ªã": len(self.student_behavior_counts)
                }, {
                    "Ch·ªâ s·ªë": "Th·ªùi gian (gi√¢y)",
                    "Gi√° tr·ªã": self.recorded_time
                }, {
                    "Ch·ªâ s·ªë": "Ng∆∞·ª°ng tin c·∫≠y",
                    "Gi√° tr·ªã": self.confidence_threshold
                }]
                pd.DataFrame(stats_data).to_excel(writer, sheet_name="Th·ªëng k√™", index=False)

            messagebox.showinfo("Th√†nh c√¥ng", f"ƒê√£ xu·∫•t b√°o c√°o Excel:\n{excel_file}")
        except ImportError:
            messagebox.showerror("L·ªói", "C·∫ßn c√†i ƒë·∫∑t pandas:\npip install pandas openpyxl")
        except Exception as e:
            LOG.exception("L·ªói export_excel_report: %s", e)
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ xu·∫•t Excel: {e}")

    def update_camera(self):
        """H√†m ƒë∆∞·ª£c g·ªçi ƒë·ªãnh k·ª≥ ƒë·ªÉ ƒë·ªçc frame t·ª´ camera."""
        try:
            if self.cap and getattr(self.cap, "isOpened", lambda: False)() and self.main_frame.winfo_ismapped():
                ret, frame = self.cap.read()
                if ret and frame is not None:
                    h0, w0 = frame.shape[:2]
                    vw = max(320, self.video_label.winfo_width())
                    vh = max(240, self.video_label.winfo_height())
                    scale = min(vw / w0, vh / h0) if w0 and h0 else 1.0
                    new_w = max(320, int(w0 * scale))
                    new_h = max(240, int(h0 * scale))

                    resized_bgr = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_AREA)

                    # Object detection & counting
                    try:
                        annotated = self.detect_objects_and_count(resized_bgr)
                    except Exception:
                        LOG.exception("L·ªói detect_objects_and_count")
                        annotated = resized_bgr

                    # Convert BGR->RGB for Tk display
                    frame_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)
                    imgtk = ImageTk.PhotoImage(Image.fromarray(frame_rgb))
                    self.video_label.imgtk = imgtk
                    self.video_label.configure(image=imgtk)
                    self.frame_size = (new_w, new_h)

                    # Update status label
                    status = f"üü¢ Camera {self.current_cam_index} ƒëang b·∫≠t"
                    if self.counting:
                        elapsed = int(time.time() - self.start_time) if self.start_time else 0
                        status += f" (ƒêang ƒë·∫øm - {elapsed}s)"
                    else:
                        parts = []
                        if self.student_detection_enabled.get():
                            parts.append("Nh·∫≠n di·ªán h·ªçc sinh: B·∫¨T")
                        if self.detection_enabled.get():
                            parts.append("Nh·∫≠n di·ªán h√†nh vi: B·∫¨T")
                        status += f" ({', '.join(parts)})" if parts else " ‚Äì s·∫µn s√†ng ƒë·∫øm."
                    self.info_label.config(text=status)
                else:
                    self.video_label.configure(image="")
        except Exception:
            LOG.exception("L·ªói update_camera")
        finally:
            self.root.after(30, self.update_camera)

    def on_close(self):
        if self.counting:
            if not messagebox.askyesno("ƒêang ƒë·∫øm", "ƒêang ƒë·∫øm h√†nh vi. Mu·ªën d·ª´ng v√† tho√°t?"):
                return
            self.stop_counting()
        try:
            if self.cap and getattr(self.cap, "isOpened", lambda: False)():
                self.cap.release()
        except Exception:
            pass
        self.root.destroy()

    def __del__(self):
        try:
            if self.cap and getattr(self.cap, "isOpened", lambda: False)():
                self.cap.release()
        except Exception:
            pass


if __name__ == "__main__":
    root = tk.Tk()
    app = PastelCameraApp(root)
    root.mainloop()